{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.972624798711755,
  "eval_steps": 500,
  "global_step": 775,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0644122383252818,
      "grad_norm": 2.4994723796844482,
      "learning_rate": 1.7307692307692308e-06,
      "loss": 0.707,
      "step": 10
    },
    {
      "epoch": 0.1288244766505636,
      "grad_norm": 3.921302318572998,
      "learning_rate": 3.653846153846154e-06,
      "loss": 0.6759,
      "step": 20
    },
    {
      "epoch": 0.1932367149758454,
      "grad_norm": 2.2829246520996094,
      "learning_rate": 5.576923076923077e-06,
      "loss": 0.6218,
      "step": 30
    },
    {
      "epoch": 0.2576489533011272,
      "grad_norm": 1.2307153940200806,
      "learning_rate": 7.5e-06,
      "loss": 0.5184,
      "step": 40
    },
    {
      "epoch": 0.322061191626409,
      "grad_norm": 0.4932824373245239,
      "learning_rate": 9.423076923076923e-06,
      "loss": 0.3863,
      "step": 50
    },
    {
      "epoch": 0.3864734299516908,
      "grad_norm": 0.4827813506126404,
      "learning_rate": 1.1346153846153845e-05,
      "loss": 0.3096,
      "step": 60
    },
    {
      "epoch": 0.45088566827697263,
      "grad_norm": 0.42843613028526306,
      "learning_rate": 1.3269230769230769e-05,
      "loss": 0.3003,
      "step": 70
    },
    {
      "epoch": 0.5152979066022544,
      "grad_norm": 0.2883773446083069,
      "learning_rate": 1.4999923815833291e-05,
      "loss": 0.2964,
      "step": 80
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.25007468461990356,
      "learning_rate": 1.4990783588445883e-05,
      "loss": 0.2848,
      "step": 90
    },
    {
      "epoch": 0.644122383252818,
      "grad_norm": 0.2500636875629425,
      "learning_rate": 1.4966427802041422e-05,
      "loss": 0.2515,
      "step": 100
    },
    {
      "epoch": 0.7085346215780999,
      "grad_norm": 0.24625274538993835,
      "learning_rate": 1.492690592900168e-05,
      "loss": 0.2656,
      "step": 110
    },
    {
      "epoch": 0.7729468599033816,
      "grad_norm": 0.28487828373908997,
      "learning_rate": 1.4872298247629265e-05,
      "loss": 0.2563,
      "step": 120
    },
    {
      "epoch": 0.8373590982286635,
      "grad_norm": 0.2912895083427429,
      "learning_rate": 1.4802715679083343e-05,
      "loss": 0.2345,
      "step": 130
    },
    {
      "epoch": 0.9017713365539453,
      "grad_norm": 0.25503090023994446,
      "learning_rate": 1.471829956207245e-05,
      "loss": 0.2315,
      "step": 140
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 0.29563114047050476,
      "learning_rate": 1.4619221365762013e-05,
      "loss": 0.22,
      "step": 150
    },
    {
      "epoch": 1.0257648953301126,
      "grad_norm": 0.3490637540817261,
      "learning_rate": 1.4505682341479816e-05,
      "loss": 0.252,
      "step": 160
    },
    {
      "epoch": 1.0901771336553945,
      "grad_norm": 0.29061833024024963,
      "learning_rate": 1.4377913113926772e-05,
      "loss": 0.2245,
      "step": 170
    },
    {
      "epoch": 1.1545893719806763,
      "grad_norm": 0.287045419216156,
      "learning_rate": 1.4236173212723442e-05,
      "loss": 0.2256,
      "step": 180
    },
    {
      "epoch": 1.2190016103059582,
      "grad_norm": 0.2783637046813965,
      "learning_rate": 1.4080750545243779e-05,
      "loss": 0.2265,
      "step": 190
    },
    {
      "epoch": 1.2834138486312399,
      "grad_norm": 0.27428391575813293,
      "learning_rate": 1.3911960811806943e-05,
      "loss": 0.2157,
      "step": 200
    },
    {
      "epoch": 1.3478260869565217,
      "grad_norm": 0.30340105295181274,
      "learning_rate": 1.3730146864415032e-05,
      "loss": 0.2208,
      "step": 210
    },
    {
      "epoch": 1.4122383252818036,
      "grad_norm": 0.34365344047546387,
      "learning_rate": 1.353567801033931e-05,
      "loss": 0.2192,
      "step": 220
    },
    {
      "epoch": 1.4766505636070852,
      "grad_norm": 0.3068559467792511,
      "learning_rate": 1.33289492619695e-05,
      "loss": 0.2047,
      "step": 230
    },
    {
      "epoch": 1.541062801932367,
      "grad_norm": 0.27162590622901917,
      "learning_rate": 1.3110380534449883e-05,
      "loss": 0.2288,
      "step": 240
    },
    {
      "epoch": 1.605475040257649,
      "grad_norm": 0.34293168783187866,
      "learning_rate": 1.2880415792732005e-05,
      "loss": 0.212,
      "step": 250
    },
    {
      "epoch": 1.6698872785829306,
      "grad_norm": 0.30702194571495056,
      "learning_rate": 1.2639522149776494e-05,
      "loss": 0.206,
      "step": 260
    },
    {
      "epoch": 1.7342995169082127,
      "grad_norm": 0.27955687046051025,
      "learning_rate": 1.2388188917735804e-05,
      "loss": 0.2027,
      "step": 270
    },
    {
      "epoch": 1.7987117552334944,
      "grad_norm": 0.3110833168029785,
      "learning_rate": 1.2126926614045114e-05,
      "loss": 0.1924,
      "step": 280
    },
    {
      "epoch": 1.863123993558776,
      "grad_norm": 0.32827866077423096,
      "learning_rate": 1.185626592444028e-05,
      "loss": 0.1929,
      "step": 290
    },
    {
      "epoch": 1.927536231884058,
      "grad_norm": 0.37161344289779663,
      "learning_rate": 1.157675662500916e-05,
      "loss": 0.2126,
      "step": 300
    },
    {
      "epoch": 1.9919484702093397,
      "grad_norm": 0.3659681975841522,
      "learning_rate": 1.1288966465465931e-05,
      "loss": 0.2143,
      "step": 310
    },
    {
      "epoch": 2.0515297906602252,
      "grad_norm": 0.3396352231502533,
      "learning_rate": 1.0993480015916695e-05,
      "loss": 0.198,
      "step": 320
    },
    {
      "epoch": 2.1159420289855073,
      "grad_norm": 0.3498600423336029,
      "learning_rate": 1.0690897479458866e-05,
      "loss": 0.1995,
      "step": 330
    },
    {
      "epoch": 2.180354267310789,
      "grad_norm": 0.2714495360851288,
      "learning_rate": 1.0381833473026259e-05,
      "loss": 0.1935,
      "step": 340
    },
    {
      "epoch": 2.244766505636071,
      "grad_norm": 0.3326718807220459,
      "learning_rate": 1.0066915778956248e-05,
      "loss": 0.2051,
      "step": 350
    },
    {
      "epoch": 2.3091787439613527,
      "grad_norm": 0.40434494614601135,
      "learning_rate": 9.74678406981487e-06,
      "loss": 0.1931,
      "step": 360
    },
    {
      "epoch": 2.3735909822866343,
      "grad_norm": 0.3628864884376526,
      "learning_rate": 9.422088609070043e-06,
      "loss": 0.2102,
      "step": 370
    },
    {
      "epoch": 2.4380032206119164,
      "grad_norm": 0.41781479120254517,
      "learning_rate": 9.09348893025217e-06,
      "loss": 0.2097,
      "step": 380
    },
    {
      "epoch": 2.502415458937198,
      "grad_norm": 0.3592340648174286,
      "learning_rate": 8.761652497285012e-06,
      "loss": 0.1893,
      "step": 390
    },
    {
      "epoch": 2.5668276972624797,
      "grad_norm": 0.3832635283470154,
      "learning_rate": 8.427253348708095e-06,
      "loss": 0.1979,
      "step": 400
    },
    {
      "epoch": 2.631239935587762,
      "grad_norm": 0.32721060514450073,
      "learning_rate": 8.090970728544467e-06,
      "loss": 0.1894,
      "step": 410
    },
    {
      "epoch": 2.6956521739130435,
      "grad_norm": 0.41297486424446106,
      "learning_rate": 7.75348770659492e-06,
      "loss": 0.2014,
      "step": 420
    },
    {
      "epoch": 2.760064412238325,
      "grad_norm": 0.3981127142906189,
      "learning_rate": 7.4154897909611215e-06,
      "loss": 0.1994,
      "step": 430
    },
    {
      "epoch": 2.824476650563607,
      "grad_norm": 0.3640437722206116,
      "learning_rate": 7.077663535615992e-06,
      "loss": 0.1943,
      "step": 440
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.30864205956459045,
      "learning_rate": 6.740695145849682e-06,
      "loss": 0.1991,
      "step": 450
    },
    {
      "epoch": 2.9533011272141705,
      "grad_norm": 0.3493393063545227,
      "learning_rate": 6.405269084423768e-06,
      "loss": 0.2056,
      "step": 460
    },
    {
      "epoch": 3.0128824476650564,
      "grad_norm": 0.3213781714439392,
      "learning_rate": 6.072066681264986e-06,
      "loss": 0.1745,
      "step": 470
    },
    {
      "epoch": 3.077294685990338,
      "grad_norm": 0.37223660945892334,
      "learning_rate": 5.7417647495224615e-06,
      "loss": 0.1799,
      "step": 480
    },
    {
      "epoch": 3.14170692431562,
      "grad_norm": 0.3605028986930847,
      "learning_rate": 5.415034210799586e-06,
      "loss": 0.1959,
      "step": 490
    },
    {
      "epoch": 3.206119162640902,
      "grad_norm": 0.4158764183521271,
      "learning_rate": 5.0925387323530555e-06,
      "loss": 0.1787,
      "step": 500
    },
    {
      "epoch": 3.206119162640902,
      "eval_loss": 0.21318674087524414,
      "eval_runtime": 46.7691,
      "eval_samples_per_second": 11.803,
      "eval_steps_per_second": 11.803,
      "step": 500
    },
    {
      "epoch": 3.2705314009661834,
      "grad_norm": 0.38720810413360596,
      "learning_rate": 4.774933379027165e-06,
      "loss": 0.1797,
      "step": 510
    },
    {
      "epoch": 3.3349436392914655,
      "grad_norm": 0.541191577911377,
      "learning_rate": 4.4628632826616815e-06,
      "loss": 0.1944,
      "step": 520
    },
    {
      "epoch": 3.399355877616747,
      "grad_norm": 0.3361659049987793,
      "learning_rate": 4.156962331675964e-06,
      "loss": 0.1992,
      "step": 530
    },
    {
      "epoch": 3.463768115942029,
      "grad_norm": 0.3468113839626312,
      "learning_rate": 3.8578518834911936e-06,
      "loss": 0.1957,
      "step": 540
    },
    {
      "epoch": 3.528180354267311,
      "grad_norm": 0.3188393712043762,
      "learning_rate": 3.566139502405979e-06,
      "loss": 0.1961,
      "step": 550
    },
    {
      "epoch": 3.5925925925925926,
      "grad_norm": 0.2837955057621002,
      "learning_rate": 3.2824177254891073e-06,
      "loss": 0.1843,
      "step": 560
    },
    {
      "epoch": 3.6570048309178746,
      "grad_norm": 0.3386957347393036,
      "learning_rate": 3.0072628589961448e-06,
      "loss": 0.1797,
      "step": 570
    },
    {
      "epoch": 3.7214170692431563,
      "grad_norm": 0.4485565423965454,
      "learning_rate": 2.741233807754674e-06,
      "loss": 0.1871,
      "step": 580
    },
    {
      "epoch": 3.785829307568438,
      "grad_norm": 0.33708542585372925,
      "learning_rate": 2.4848709398959574e-06,
      "loss": 0.181,
      "step": 590
    },
    {
      "epoch": 3.85024154589372,
      "grad_norm": 0.4070965051651001,
      "learning_rate": 2.2386949892390503e-06,
      "loss": 0.2029,
      "step": 600
    },
    {
      "epoch": 3.9146537842190017,
      "grad_norm": 0.43558090925216675,
      "learning_rate": 2.0032059975568227e-06,
      "loss": 0.1913,
      "step": 610
    },
    {
      "epoch": 3.9790660225442833,
      "grad_norm": 0.39736372232437134,
      "learning_rate": 1.7788822988724846e-06,
      "loss": 0.196,
      "step": 620
    },
    {
      "epoch": 4.038647342995169,
      "grad_norm": 0.3438693881034851,
      "learning_rate": 1.5661795478496513e-06,
      "loss": 0.1929,
      "step": 630
    },
    {
      "epoch": 4.1030595813204505,
      "grad_norm": 0.3298947215080261,
      "learning_rate": 1.3655297942496178e-06,
      "loss": 0.1851,
      "step": 640
    },
    {
      "epoch": 4.1674718196457325,
      "grad_norm": 0.3207039535045624,
      "learning_rate": 1.1773406053357568e-06,
      "loss": 0.1855,
      "step": 650
    },
    {
      "epoch": 4.231884057971015,
      "grad_norm": 0.3679065704345703,
      "learning_rate": 1.0019942380076946e-06,
      "loss": 0.1861,
      "step": 660
    },
    {
      "epoch": 4.296296296296296,
      "grad_norm": 0.3311655819416046,
      "learning_rate": 8.3984686234684e-07,
      "loss": 0.189,
      "step": 670
    },
    {
      "epoch": 4.360708534621578,
      "grad_norm": 0.3896726965904236,
      "learning_rate": 6.912278381504259e-07,
      "loss": 0.1866,
      "step": 680
    },
    {
      "epoch": 4.42512077294686,
      "grad_norm": 0.36079713702201843,
      "learning_rate": 5.564390459236148e-07,
      "loss": 0.188,
      "step": 690
    },
    {
      "epoch": 4.489533011272142,
      "grad_norm": 0.36433908343315125,
      "learning_rate": 4.3575427368854335e-07,
      "loss": 0.1791,
      "step": 700
    },
    {
      "epoch": 4.553945249597423,
      "grad_norm": 0.3881284296512604,
      "learning_rate": 3.2941866085589525e-07,
      "loss": 0.1821,
      "step": 710
    },
    {
      "epoch": 4.618357487922705,
      "grad_norm": 0.37586843967437744,
      "learning_rate": 2.3764820028857327e-07,
      "loss": 0.1878,
      "step": 720
    },
    {
      "epoch": 4.6827697262479875,
      "grad_norm": 0.41608259081840515,
      "learning_rate": 1.6062929956894817e-07,
      "loss": 0.1887,
      "step": 730
    },
    {
      "epoch": 4.747181964573269,
      "grad_norm": 0.42331650853157043,
      "learning_rate": 9.851840236082265e-08,
      "loss": 0.1906,
      "step": 740
    },
    {
      "epoch": 4.811594202898551,
      "grad_norm": 0.339131236076355,
      "learning_rate": 5.144167063522776e-08,
      "loss": 0.1785,
      "step": 750
    },
    {
      "epoch": 4.876006441223833,
      "grad_norm": 0.36757004261016846,
      "learning_rate": 1.9494728405516083e-08,
      "loss": 0.1938,
      "step": 760
    },
    {
      "epoch": 4.940418679549114,
      "grad_norm": 0.3186508119106293,
      "learning_rate": 2.7424674923062777e-09,
      "loss": 0.1714,
      "step": 770
    },
    {
      "epoch": 4.972624798711755,
      "step": 775,
      "total_flos": 5.394434972838789e+17,
      "train_loss": 0.23085679254224223,
      "train_runtime": 6855.2601,
      "train_samples_per_second": 3.622,
      "train_steps_per_second": 0.113
    }
  ],
  "logging_steps": 10,
  "max_steps": 775,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.394434972838789e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
