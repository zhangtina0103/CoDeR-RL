transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.3,>=4.45.0
datasets<=3.5.0,>=2.16.0
accelerate<=1.6.0,>=0.34.0
peft<=0.15.1,>=0.14.0
trl<=0.9.6,>=0.8.6
tokenizers<=0.21.1,>=0.19.0
gradio<=5.25.0,>=4.38.0
scipy
einops
sentencepiece
tiktoken
protobuf
uvicorn
fastapi
sse-starlette
matplotlib>=3.7.0
fire
omegaconf
packaging
pyyaml
numpy<2.0.0
pydantic<=2.10.6
pandas>=2.0.0
av
librosa
tyro<0.9.0

[adam-mini]
adam-mini

[apollo]
apollo-torch

[aqlm]
aqlm[gpu]>=1.1.0

[awq]
autoawq

[badam]
badam>=1.2.1

[bitsandbytes]
bitsandbytes>=0.39.0

[deepspeed]
deepspeed<=0.16.5,>=0.10.0

[dev]
pre-commit
ruff
pytest
build

[eetq]
eetq

[galore]
galore-torch

[gptq]
optimum>=1.17.0
auto-gptq>=0.5.0

[hqq]
hqq

[liger-kernel]
liger-kernel>=0.5.5

[metrics]
nltk
jieba
rouge-chinese

[minicpm_v]
soundfile
torchvision
torchaudio
vector_quantize_pytorch
vocos
msgpack
referencing
jsonschema_specifications
transformers==4.48.3

[modelscope]
modelscope

[openmind]
openmind

[qwen]
transformers_stream_generator

[sglang]
sglang[srt]>=0.4.5
transformers==4.51.1

[swanlab]
swanlab

[torch]
torch>=1.13.1

[torch-npu]
torch==2.4.0
torch-npu==2.4.0.post2
decorator

[vllm]
vllm<=0.8.4,>=0.4.3
